{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e3c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6b1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from mindcraft.torch.module import FeedForward, Conv, ConvT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60aba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = \"Sigmoid\"\n",
    "device = \"cuda\"  # \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd068851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(num_parameters, latent_size, kernels, strides, filters, foo, dropout=0.1, batch_norm=False, verbose=True):\n",
    "    cnn_reduction = Conv.get_cnn_output_size(input_size=num_parameters, kernel_size=kernels, stride=strides)\n",
    "    cnn_output_size = cnn_reduction[-1] * filters[-1]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"CNN-reductions from input {num_parameters}: \", cnn_reduction)\n",
    "        print(\"Final CNN-flatten-size to latent-size:\", cnn_output_size, \"->\", latent_size)\n",
    "\n",
    "    flatten_size = cnn_reduction[-1] * filters[-1]\n",
    "\n",
    "    if dropout:\n",
    "        dropout = [dropout] * len(kernels)\n",
    "\n",
    "    if batch_norm:\n",
    "        batch_norm = [True] * len(kernels)\n",
    "\n",
    "    encoder = Conv(input_size=1, input_dim=1,\n",
    "                   filters=filters,\n",
    "                   strides=strides,\n",
    "                   kernel_size=kernels,\n",
    "                   dropout=dropout,\n",
    "                   batch_norm=batch_norm,\n",
    "                   activation=activation,\n",
    "                   flatten=dict(cls=FeedForward, input_size=flatten_size, output_size=latent_size),\n",
    "                  )\n",
    "\n",
    "    if verbose:\n",
    "        import torch\n",
    "        x = torch.randn(1, 1, num_parameters)\n",
    "        print(\"\\n{0:<22s}\".format(\"encoder input:\"), x.shape)\n",
    "        for cnn in encoder.cnn:\n",
    "            x = cnn(x)\n",
    "            print(\"- {0:<20s} output:\".format(str(cnn.__class__.__name__)), x.shape)\n",
    "    \n",
    "        print()\n",
    "        print(encoder.parameters_str)\n",
    "        \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41edeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(num_parameters, latent_size, kernels, strides, filters, foo, dropout=0.1, batch_norm=False, verbose=True,\n",
    "                padding=None, output_padding=None):\n",
    "    convt_unfold = ConvT.get_output_size(input_size=latent_size, kernel_size=kernels, stride=strides, \n",
    "                                         padding=padding, output_padding=output_padding)\n",
    "    unfold_size = convt_unfold[-1] * filters[-1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ConvT-unfold from latent {latent_size}: \", convt_unfold)\n",
    "\n",
    "    if dropout:\n",
    "        dropout = [dropout] * (len(kernels) - 1) + [None]\n",
    "\n",
    "    if batch_norm:\n",
    "        batch_norm = [True] * (len(kernels) - 1) + [None]\n",
    "\n",
    "    decoder = ConvT(input_size=1, input_dim=1,\n",
    "                    filters=filters,\n",
    "                    kernel_size=kernels,\n",
    "                    strides=strides,\n",
    "                    activation=foo,\n",
    "                    dropout=dropout,\n",
    "                    batch_norm=batch_norm,\n",
    "                    padding=padding or 0,\n",
    "                    output_padding=output_padding or 0,\n",
    "                    flatten=True,  # dict(cls=FeedForward, input_size=unfold_size, output_size=num_parameters),\n",
    "                    )\n",
    "\n",
    "    if verbose:\n",
    "        x = torch.randn(1, 1, latent_size)\n",
    "        print(\"\\n{0:<22s}\".format(\"decoder input:\"), x.shape)\n",
    "        for cnn in decoder.cnn_t:\n",
    "            x = cnn(x)\n",
    "            print(\"- {0:<20s} output:\".format(str(cnn.__class__.__name__)), x.shape)  \n",
    "\n",
    "        print()\n",
    "        print(decoder.parameters_str)\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c85ab8",
   "metadata": {},
   "source": [
    "## CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef46f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = 178\n",
    "latent_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52ce0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-reductions from input 178:  (175, 86, 42, 10)\n",
      "Final CNN-flatten-size to latent-size: 160 -> 9\n",
      "\n",
      "encoder input:         torch.Size([1, 1, 178])\n",
      "- Conv1d               output: torch.Size([1, 8, 175])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 175])\n",
      "- Sigmoid              output: torch.Size([1, 8, 175])\n",
      "- Dropout              output: torch.Size([1, 8, 175])\n",
      "- Conv1d               output: torch.Size([1, 8, 86])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 86])\n",
      "- Sigmoid              output: torch.Size([1, 8, 86])\n",
      "- Dropout              output: torch.Size([1, 8, 86])\n",
      "- Conv1d               output: torch.Size([1, 8, 42])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 42])\n",
      "- Sigmoid              output: torch.Size([1, 8, 42])\n",
      "- Dropout              output: torch.Size([1, 8, 42])\n",
      "- Conv1d               output: torch.Size([1, 16, 10])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 10])\n",
      "- Sigmoid              output: torch.Size([1, 16, 10])\n",
      "- Dropout              output: torch.Size([1, 16, 10])\n",
      "- Flatten              output: torch.Size([1, 160])\n",
      "- FeedForward          output: torch.Size([1, 9])\n",
      "\n",
      "============================\n",
      "Conv\n",
      "============================\n",
      "cnn.0.weight\t(8, 1, 4)\n",
      "cnn.0.bias\t(8,)\n",
      "cnn.4.weight\t(8, 8, 4)\n",
      "cnn.4.bias\t(8,)\n",
      "cnn.8.weight\t(8, 8, 4)\n",
      "cnn.8.bias\t(8,)\n",
      "cnn.12.weight\t(16, 8, 6)\n",
      "cnn.12.bias\t(16,)\n",
      "cnn.17.nn.0.weight\t(9, 160)\n",
      "cnn.17.nn.0.bias\t(9,)\n",
      "============================\n",
      "num-params    : 2801\n",
      "num-trainables: 2801\n",
      "============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_strides = [1, 2, 2, 4]\n",
    "encoder_filters = [8, 8, 8, 16]\n",
    "encoder_kernels = [4, 4, 4, 6]\n",
    "\n",
    "activation = [\"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\"]\n",
    "\n",
    "encoder = get_encoder(num_parameters, latent_size, \n",
    "                      kernels=encoder_kernels, strides=encoder_strides, filters=encoder_filters, foo=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac6b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = 178\n",
    "latent_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c24995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-reductions from input 178:  (88, 43, 21, 18)\n",
      "Final CNN-flatten-size to latent-size: 18 -> 16\n",
      "\n",
      "encoder input:         torch.Size([1, 1, 178])\n",
      "- Conv1d               output: torch.Size([1, 4, 88])\n",
      "- BatchNorm1d          output: torch.Size([1, 4, 88])\n",
      "- Sigmoid              output: torch.Size([1, 4, 88])\n",
      "- Dropout              output: torch.Size([1, 4, 88])\n",
      "- Conv1d               output: torch.Size([1, 8, 43])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 43])\n",
      "- Sigmoid              output: torch.Size([1, 8, 43])\n",
      "- Dropout              output: torch.Size([1, 8, 43])\n",
      "- Conv1d               output: torch.Size([1, 16, 21])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 21])\n",
      "- Sigmoid              output: torch.Size([1, 16, 21])\n",
      "- Dropout              output: torch.Size([1, 16, 21])\n",
      "- Conv1d               output: torch.Size([1, 1, 18])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 18])\n",
      "- Sigmoid              output: torch.Size([1, 1, 18])\n",
      "- Dropout              output: torch.Size([1, 1, 18])\n",
      "- Flatten              output: torch.Size([1, 18])\n",
      "- FeedForward          output: torch.Size([1, 16])\n",
      "\n",
      "============================\n",
      "Conv\n",
      "============================\n",
      "cnn.0.weight\t(4, 1, 3)\n",
      "cnn.0.bias\t(4,)\n",
      "cnn.4.weight\t(8, 4, 3)\n",
      "cnn.4.bias\t(8,)\n",
      "cnn.8.weight\t(16, 8, 3)\n",
      "cnn.8.bias\t(16,)\n",
      "cnn.12.weight\t(1, 16, 4)\n",
      "cnn.12.bias\t(1,)\n",
      "cnn.17.nn.0.weight\t(16, 18)\n",
      "cnn.17.nn.0.bias\t(16,)\n",
      "============================\n",
      "num-params    : 889\n",
      "num-trainables: 889\n",
      "============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_strides = [2, 2, 2, 1]\n",
    "encoder_kernels = [3, 3, 3, 4]\n",
    "encoder_filters = [4, 8, 16, 1]\n",
    "activation = [\"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\"]\n",
    "\n",
    "encoder = get_encoder(num_parameters, latent_size, \n",
    "                      kernels=encoder_kernels, strides=encoder_strides, filters=encoder_filters, foo=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3da4c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvT-unfold from latent 16:  (18, 21, 43, 88, 178)\n",
      "\n",
      "decoder input:         torch.Size([1, 1, 16])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 18])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 18])\n",
      "- Dropout              output: torch.Size([1, 32, 18])\n",
      "- ConvTranspose1d      output: torch.Size([1, 16, 21])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 21])\n",
      "- Dropout              output: torch.Size([1, 16, 21])\n",
      "- ConvTranspose1d      output: torch.Size([1, 16, 43])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 43])\n",
      "- Dropout              output: torch.Size([1, 16, 43])\n",
      "- ConvTranspose1d      output: torch.Size([1, 8, 88])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 88])\n",
      "- Dropout              output: torch.Size([1, 8, 88])\n",
      "- ConvTranspose1d      output: torch.Size([1, 1, 178])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 178])\n",
      "- Flatten              output: torch.Size([1, 178])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 32, 3)\n",
      "cnn_t.0.bias\t(32,)\n",
      "cnn_t.3.weight\t(32, 16, 4)\n",
      "cnn_t.3.bias\t(16,)\n",
      "cnn_t.6.weight\t(16, 16, 3)\n",
      "cnn_t.6.bias\t(16,)\n",
      "cnn_t.9.weight\t(16, 8, 4)\n",
      "cnn_t.9.bias\t(8,)\n",
      "cnn_t.12.weight\t(8, 1, 4)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 3529\n",
      "num-trainables: 3529\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_kernels = [3, 4, 3, 4, 4]\n",
    "decoder_strides = [1, 1, 2, 2, 2]\n",
    "decoder_filters = [32, 16, 16, 8, 1]\n",
    "decoder_activations = [\"Sidmoig\", \"Sidmoig\", \"Sidmoig\", \"Sidmoig\", None]\n",
    "\n",
    "decoder = get_decoder(num_parameters, latent_size, kernels=decoder_kernels, strides=decoder_strides, filters=decoder_filters,\n",
    "                      foo=decoder_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e277f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = 178\n",
    "latent_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d193b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-reductions from input 178:  (88, 43, 21, 18)\n",
      "Final CNN-flatten-size to latent-size: 18 -> 4\n",
      "\n",
      "encoder input:         torch.Size([1, 1, 178])\n",
      "- Conv1d               output: torch.Size([1, 4, 88])\n",
      "- BatchNorm1d          output: torch.Size([1, 4, 88])\n",
      "- Sigmoid              output: torch.Size([1, 4, 88])\n",
      "- Dropout              output: torch.Size([1, 4, 88])\n",
      "- Conv1d               output: torch.Size([1, 8, 43])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 43])\n",
      "- Sigmoid              output: torch.Size([1, 8, 43])\n",
      "- Dropout              output: torch.Size([1, 8, 43])\n",
      "- Conv1d               output: torch.Size([1, 16, 21])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 21])\n",
      "- Sigmoid              output: torch.Size([1, 16, 21])\n",
      "- Dropout              output: torch.Size([1, 16, 21])\n",
      "- Conv1d               output: torch.Size([1, 1, 18])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 18])\n",
      "- Sigmoid              output: torch.Size([1, 1, 18])\n",
      "- Dropout              output: torch.Size([1, 1, 18])\n",
      "- Flatten              output: torch.Size([1, 18])\n",
      "- FeedForward          output: torch.Size([1, 4])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 32, 3)\n",
      "cnn_t.0.bias\t(32,)\n",
      "cnn_t.3.weight\t(32, 16, 4)\n",
      "cnn_t.3.bias\t(16,)\n",
      "cnn_t.6.weight\t(16, 16, 3)\n",
      "cnn_t.6.bias\t(16,)\n",
      "cnn_t.9.weight\t(16, 8, 4)\n",
      "cnn_t.9.bias\t(8,)\n",
      "cnn_t.12.weight\t(8, 1, 4)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 3529\n",
      "num-trainables: 3529\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_strides = [2, 2, 2, 1]\n",
    "encoder_kernels = [3, 3, 3, 4]\n",
    "encoder_filters = [4, 8, 16, 1]\n",
    "activation = [\"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\"]\n",
    "\n",
    "encoder = get_encoder(num_parameters, latent_size, \n",
    "                      kernels=encoder_kernels, strides=encoder_strides, filters=encoder_filters, foo=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2c40662a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvT-unfold from latent 4:  (18, 21, 43, 88, 178)\n",
      "Final ConvT-flatten-size to latent-size: 21 -> 4\n",
      "\n",
      "decoder input:         torch.Size([1, 1, 4])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 18])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 18])\n",
      "- Dropout              output: torch.Size([1, 32, 18])\n",
      "- ConvTranspose1d      output: torch.Size([1, 16, 21])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 21])\n",
      "- Dropout              output: torch.Size([1, 16, 21])\n",
      "- ConvTranspose1d      output: torch.Size([1, 16, 43])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 43])\n",
      "- Dropout              output: torch.Size([1, 16, 43])\n",
      "- ConvTranspose1d      output: torch.Size([1, 8, 88])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 88])\n",
      "- Dropout              output: torch.Size([1, 8, 88])\n",
      "- ConvTranspose1d      output: torch.Size([1, 1, 178])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 178])\n",
      "- Flatten              output: torch.Size([1, 178])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 32, 6)\n",
      "cnn_t.0.bias\t(32,)\n",
      "cnn_t.3.weight\t(32, 16, 4)\n",
      "cnn_t.3.bias\t(16,)\n",
      "cnn_t.6.weight\t(16, 16, 3)\n",
      "cnn_t.6.bias\t(16,)\n",
      "cnn_t.9.weight\t(16, 8, 4)\n",
      "cnn_t.9.bias\t(8,)\n",
      "cnn_t.12.weight\t(8, 1, 4)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 3625\n",
      "num-trainables: 3625\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_kernels = [6, 4, 3, 4, 4]\n",
    "decoder_strides = [4, 1, 2, 2, 2]\n",
    "decoder_filters = [32, 16, 16, 8, 1]\n",
    "decoder_activations = [\"Sidmoig\", \"Sidmoig\", \"Sidmoig\", \"Sidmoig\", None]\n",
    "\n",
    "decoder = get_decoder(num_parameters, latent_size, kernels=decoder_kernels, strides=decoder_strides, filters=decoder_filters,\n",
    "                      foo=decoder_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bea7e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = 178\n",
    "latent_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d001e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-reductions from input 178:  (88, 43, 21, 18)\n",
      "Final CNN-flatten-size to latent-size: 18 -> 2\n",
      "\n",
      "encoder input:         torch.Size([1, 1, 178])\n",
      "- Conv1d               output: torch.Size([1, 4, 88])\n",
      "- BatchNorm1d          output: torch.Size([1, 4, 88])\n",
      "- Sigmoid              output: torch.Size([1, 4, 88])\n",
      "- Dropout              output: torch.Size([1, 4, 88])\n",
      "- Conv1d               output: torch.Size([1, 8, 43])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 43])\n",
      "- Sigmoid              output: torch.Size([1, 8, 43])\n",
      "- Dropout              output: torch.Size([1, 8, 43])\n",
      "- Conv1d               output: torch.Size([1, 16, 21])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 21])\n",
      "- Sigmoid              output: torch.Size([1, 16, 21])\n",
      "- Dropout              output: torch.Size([1, 16, 21])\n",
      "- Conv1d               output: torch.Size([1, 1, 18])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 18])\n",
      "- Sigmoid              output: torch.Size([1, 1, 18])\n",
      "- Dropout              output: torch.Size([1, 1, 18])\n",
      "- Flatten              output: torch.Size([1, 18])\n",
      "- FeedForward          output: torch.Size([1, 2])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 32, 6)\n",
      "cnn_t.0.bias\t(32,)\n",
      "cnn_t.3.weight\t(32, 16, 4)\n",
      "cnn_t.3.bias\t(16,)\n",
      "cnn_t.6.weight\t(16, 16, 3)\n",
      "cnn_t.6.bias\t(16,)\n",
      "cnn_t.9.weight\t(16, 8, 4)\n",
      "cnn_t.9.bias\t(8,)\n",
      "cnn_t.12.weight\t(8, 1, 4)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 3625\n",
      "num-trainables: 3625\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_strides = [2, 2, 2, 1]\n",
    "encoder_kernels = [3, 3, 3, 4]\n",
    "encoder_filters = [4, 8, 16, 1]\n",
    "activation = [\"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\"]\n",
    "\n",
    "encoder = get_encoder(num_parameters, latent_size, \n",
    "                      kernels=encoder_kernels, strides=encoder_strides, filters=encoder_filters, foo=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6c58a355",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvT-unfold from latent 4:  (18, 21, 43, 88, 178)\n",
      "Final ConvT-flatten-size to latent-size: 21 -> 4\n",
      "\n",
      "decoder input:         torch.Size([1, 1, 4])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 18])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 18])\n",
      "- Dropout              output: torch.Size([1, 32, 18])\n",
      "- ConvTranspose1d      output: torch.Size([1, 16, 21])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 21])\n",
      "- Dropout              output: torch.Size([1, 16, 21])\n",
      "- ConvTranspose1d      output: torch.Size([1, 16, 43])\n",
      "- BatchNorm1d          output: torch.Size([1, 16, 43])\n",
      "- Dropout              output: torch.Size([1, 16, 43])\n",
      "- ConvTranspose1d      output: torch.Size([1, 8, 88])\n",
      "- BatchNorm1d          output: torch.Size([1, 8, 88])\n",
      "- Dropout              output: torch.Size([1, 8, 88])\n",
      "- ConvTranspose1d      output: torch.Size([1, 1, 178])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 178])\n",
      "- Flatten              output: torch.Size([1, 178])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 32, 6)\n",
      "cnn_t.0.bias\t(32,)\n",
      "cnn_t.3.weight\t(32, 16, 4)\n",
      "cnn_t.3.bias\t(16,)\n",
      "cnn_t.6.weight\t(16, 16, 3)\n",
      "cnn_t.6.bias\t(16,)\n",
      "cnn_t.9.weight\t(16, 8, 4)\n",
      "cnn_t.9.bias\t(8,)\n",
      "cnn_t.12.weight\t(8, 1, 4)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 3625\n",
      "num-trainables: 3625\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_kernels = [6, 4, 3, 4, 4]\n",
    "decoder_strides = [4, 1, 2, 2, 2]\n",
    "decoder_filters = [32, 16, 16, 8, 1]\n",
    "decoder_activations = [\"Sidmoig\", \"Sidmoig\", \"Sidmoig\", \"Sidmoig\", None]\n",
    "\n",
    "decoder = get_decoder(num_parameters, latent_size, kernels=decoder_kernels, strides=decoder_strides, filters=decoder_filters,\n",
    "                      foo=decoder_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f72c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "00a6fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = 792\n",
    "latent_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e0439ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-reductions from input 792:  (395, 197, 98, 48, 45)\n",
      "Final CNN-flatten-size to latent-size: 45 -> 24\n",
      "\n",
      "encoder input:         torch.Size([1, 1, 792])\n",
      "- Conv1d               output: torch.Size([1, 8, 395])\n",
      "- Sigmoid              output: torch.Size([1, 8, 395])\n",
      "- Conv1d               output: torch.Size([1, 16, 197])\n",
      "- Sigmoid              output: torch.Size([1, 16, 197])\n",
      "- Conv1d               output: torch.Size([1, 32, 98])\n",
      "- Sigmoid              output: torch.Size([1, 32, 98])\n",
      "- Conv1d               output: torch.Size([1, 64, 48])\n",
      "- Sigmoid              output: torch.Size([1, 64, 48])\n",
      "- Conv1d               output: torch.Size([1, 1, 45])\n",
      "- Sigmoid              output: torch.Size([1, 1, 45])\n",
      "- Flatten              output: torch.Size([1, 45])\n",
      "- FeedForward          output: torch.Size([1, 24])\n",
      "\n",
      "============================\n",
      "Conv\n",
      "============================\n",
      "cnn.0.weight\t(8, 1, 3)\n",
      "cnn.0.bias\t(8,)\n",
      "cnn.2.weight\t(16, 8, 3)\n",
      "cnn.2.bias\t(16,)\n",
      "cnn.4.weight\t(32, 16, 3)\n",
      "cnn.4.bias\t(32,)\n",
      "cnn.6.weight\t(64, 32, 3)\n",
      "cnn.6.bias\t(64,)\n",
      "cnn.8.weight\t(1, 64, 4)\n",
      "cnn.8.bias\t(1,)\n",
      "cnn.11.nn.0.weight\t(24, 45)\n",
      "cnn.11.nn.0.bias\t(24,)\n",
      "============================\n",
      "num-params    : 9569\n",
      "num-trainables: 9569\n",
      "============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_strides = [2, 2, 2, 2, 1]\n",
    "encoder_kernels = [3, 3, 3, 3, 4]\n",
    "encoder_filters = [8, 16, 32, 64, 1]\n",
    "activation = [\"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\"]\n",
    "\n",
    "encoder = get_encoder(num_parameters, latent_size, batch_norm=None, dropout=None,\n",
    "                      kernels=encoder_kernels, strides=encoder_strides, filters=encoder_filters, foo=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "53612c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvT-unfold from latent 24:  (48, 98, 197, 395, 792)\n",
      "Final ConvT-flatten-size to latent-size: 21 -> 24\n",
      "\n",
      "decoder input:         torch.Size([1, 1, 24])\n",
      "- ConvTranspose1d      output: torch.Size([1, 64, 48])\n",
      "- BatchNorm1d          output: torch.Size([1, 64, 48])\n",
      "- Dropout              output: torch.Size([1, 64, 48])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 98])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 98])\n",
      "- Dropout              output: torch.Size([1, 32, 98])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 197])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 197])\n",
      "- Dropout              output: torch.Size([1, 32, 197])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 395])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 395])\n",
      "- Dropout              output: torch.Size([1, 32, 395])\n",
      "- ConvTranspose1d      output: torch.Size([1, 1, 792])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 792])\n",
      "- Flatten              output: torch.Size([1, 792])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 64, 2)\n",
      "cnn_t.0.bias\t(64,)\n",
      "cnn_t.3.weight\t(64, 32, 4)\n",
      "cnn_t.3.bias\t(32,)\n",
      "cnn_t.6.weight\t(32, 32, 3)\n",
      "cnn_t.6.bias\t(32,)\n",
      "cnn_t.9.weight\t(32, 32, 3)\n",
      "cnn_t.9.bias\t(32,)\n",
      "cnn_t.12.weight\t(32, 1, 4)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 14753\n",
      "num-trainables: 14753\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_kernels = [2, 4, 3, 3, 4]\n",
    "decoder_strides = [2, 2, 2, 2, 2]\n",
    "decoder_filters = [64, 32, 32, 32, 1]\n",
    "decoder_activations = [\"Sidmoig\", \"Sidmoig\", \"Sidmoig\", \"Sidmoig\", None]\n",
    "\n",
    "decoder = get_decoder(num_parameters, latent_size, kernels=decoder_kernels, strides=decoder_strides, filters=decoder_filters,\n",
    "                      foo=decoder_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06384d42",
   "metadata": {},
   "source": [
    "## BARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1135b1",
   "metadata": {},
   "source": [
    "### FF-Flat-FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37574de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = 103\n",
    "latent_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72794bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-reductions from input 103:  (51, 25, 12, 5, 3)\n",
      "Final CNN-flatten-size to latent-size: 3 -> 3\n",
      "\n",
      "encoder input:         torch.Size([1, 1, 103])\n",
      "- Conv1d               output: torch.Size([1, 8, 51])\n",
      "- Sigmoid              output: torch.Size([1, 8, 51])\n",
      "- Conv1d               output: torch.Size([1, 16, 25])\n",
      "- Sigmoid              output: torch.Size([1, 16, 25])\n",
      "- Conv1d               output: torch.Size([1, 32, 12])\n",
      "- Sigmoid              output: torch.Size([1, 32, 12])\n",
      "- Conv1d               output: torch.Size([1, 64, 5])\n",
      "- Sigmoid              output: torch.Size([1, 64, 5])\n",
      "- Conv1d               output: torch.Size([1, 1, 3])\n",
      "- Sigmoid              output: torch.Size([1, 1, 3])\n",
      "- Flatten              output: torch.Size([1, 3])\n",
      "- FeedForward          output: torch.Size([1, 3])\n",
      "\n",
      "==========================\n",
      "Conv\n",
      "==========================\n",
      "cnn.0.weight\t(8, 1, 3)\n",
      "cnn.0.bias\t(8,)\n",
      "cnn.2.weight\t(16, 8, 3)\n",
      "cnn.2.bias\t(16,)\n",
      "cnn.4.weight\t(32, 16, 3)\n",
      "cnn.4.bias\t(32,)\n",
      "cnn.6.weight\t(64, 32, 3)\n",
      "cnn.6.bias\t(64,)\n",
      "cnn.8.weight\t(1, 64, 3)\n",
      "cnn.8.bias\t(1,)\n",
      "cnn.11.nn.0.weight\t(3, 3)\n",
      "cnn.11.nn.0.bias\t(3,)\n",
      "==========================\n",
      "num-params    : 8413\n",
      "num-trainables: 8413\n",
      "==========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_strides = [2, 2, 2, 2, 1]\n",
    "encoder_kernels = [3, 3, 3, 3, 3]\n",
    "encoder_filters = [8, 16, 32, 64, 1]\n",
    "activation = [\"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\", \"Sigmoid\"]\n",
    "\n",
    "encoder = get_encoder(num_parameters, latent_size, batch_norm=None, dropout=None,\n",
    "                      kernels=encoder_kernels, strides=encoder_strides, filters=encoder_filters, foo=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1a3ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvT-unfold from latent 3:  (5, 12, 25, 51, 103)\n",
      "\n",
      "decoder input:         torch.Size([1, 1, 3])\n",
      "- ConvTranspose1d      output: torch.Size([1, 64, 5])\n",
      "- BatchNorm1d          output: torch.Size([1, 64, 5])\n",
      "- Dropout              output: torch.Size([1, 64, 5])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 12])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 12])\n",
      "- Dropout              output: torch.Size([1, 32, 12])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 25])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 25])\n",
      "- Dropout              output: torch.Size([1, 32, 25])\n",
      "- ConvTranspose1d      output: torch.Size([1, 32, 51])\n",
      "- BatchNorm1d          output: torch.Size([1, 32, 51])\n",
      "- Dropout              output: torch.Size([1, 32, 51])\n",
      "- ConvTranspose1d      output: torch.Size([1, 1, 103])\n",
      "- BatchNorm1d          output: torch.Size([1, 1, 103])\n",
      "- Flatten              output: torch.Size([1, 103])\n",
      "\n",
      "===========================\n",
      "ConvT\n",
      "===========================\n",
      "cnn_t.0.weight\t(1, 64, 3)\n",
      "cnn_t.0.bias\t(64,)\n",
      "cnn_t.3.weight\t(64, 32, 3)\n",
      "cnn_t.3.bias\t(32,)\n",
      "cnn_t.6.weight\t(32, 32, 3)\n",
      "cnn_t.6.bias\t(32,)\n",
      "cnn_t.9.weight\t(32, 32, 3)\n",
      "cnn_t.9.bias\t(32,)\n",
      "cnn_t.12.weight\t(32, 1, 3)\n",
      "cnn_t.12.bias\t(1,)\n",
      "===========================\n",
      "num-params    : 12737\n",
      "num-trainables: 12737\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_kernels = [3, 3, 3, 3, 3]\n",
    "decoder_strides = [1, 2, 2, 2, 2]\n",
    "output_padding  = [0, 1, 0, 0, 0]\n",
    "decoder_filters = [64, 32, 32, 32, 1]\n",
    "decoder_activations = [\"Sidmoig\", \"Sidmoig\", \"Sidmoig\", \"Sidmoig\", None]\n",
    "\n",
    "decoder = get_decoder(num_parameters, latent_size, kernels=decoder_kernels, strides=decoder_strides, filters=decoder_filters,\n",
    "                      foo=decoder_activations, output_padding=output_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6f44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc61c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc",
   "language": "python",
   "name": "mc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
